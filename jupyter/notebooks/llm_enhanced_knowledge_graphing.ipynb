{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d87fb61c-461d-49a2-af92-3e3a3f4058bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Collecting spacy<3.8.0,>=3.7.2 (from en-core-web-sm==3.7.1)\n",
      "  Using cached spacy-3.7.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /.venv/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /.venv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /.venv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /.venv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /.venv/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /.venv/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Using cached spacy-3.7.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (6.3 MB)\n",
      "Installing collected packages: spacy, en-core-web-sm\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.7.0\n",
      "    Uninstalling spacy-3.7.0:\n",
      "      Successfully uninstalled spacy-3.7.0\n",
      "Successfully installed en-core-web-sm-3.7.1 spacy-3.7.5\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2097b15-a5c4-4b51-8bcf-82728645cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55d8f0d-1431-411e-a240-f0bbd9fd7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp = spacy.load(\"en_core_web_md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2ddbde-12a2-40c6-a2ec-8919aa31cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample excerpt for demonstration purposes. Replace with a more detailed summary for a richer graph.\n",
    " \n",
    "summary = \"\"\"\n",
    "Holden Caulfield, a teenager in New York City, narrates the novel. Struggling with depression, he recounts his experiences in school, relationships, and his disdain for 'phonies.'\n",
    "\"\"\"\n",
    "\n",
    "# Process the summary text\n",
    "doc = nlp(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e97f60d-38e2-4290-869b-ab460a59799c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Holden Caulfield, a teenager in New York City, narrates the novel.\n",
      "Entities: [('Holden Caulfield', 'PERSON'), ('New York City', 'GPE')]\n",
      "Text: Struggling with depression, he recounts his experiences in school, relationships, and his disdain for 'phonies.'\n",
      "Entities: []\n",
      "Entity counts: Counter({'PERSON': 1, 'GPE': 1})\n"
     ]
    }
   ],
   "source": [
    "# split document into sentences\n",
    "def split_document_sent(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "# define custom relationship extraction and text processing\n",
    "def process_text(text, verbose=False):\n",
    "    doc = nlp(text)\n",
    "    if verbose:\n",
    "        print(f\"Text: {doc.text}\")\n",
    "        print(f\"Entities: {[(ent.text, ent.label_) for ent in doc.ents]}\")\n",
    "        # Relations extraction logic can be added here\n",
    "    return doc\n",
    "\n",
    "# Pipeline to run entity extraction\n",
    "def extract_entities(text, verbose=False):\n",
    "    processed_data = []\n",
    "    entity_counts = Counter()\n",
    "\n",
    "    sentences = split_document_sent(text)\n",
    "    for sent in sentences:\n",
    "        doc = process_text(sent, verbose)\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "        # Store processed data for each sentence\n",
    "        processed_data.append({'text': doc.text, 'entities': entities})\n",
    "\n",
    "        # Update counters\n",
    "        entity_counts.update([ent[1] for ent in entities])\n",
    "\n",
    "    # Export to JSON\n",
    "    with open('processed_data.json', 'w') as f:\n",
    "        json.dump(processed_data, f)\n",
    "\n",
    "    # Display summary\n",
    "    print(f\"Entity counts: {entity_counts}\")\n",
    "\n",
    "# Run the pipeline on the summary text\n",
    "verbose = True\n",
    "extract_entities(summary, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90044c27-90e7-4ee0-9f16-8365db98683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create node and relationships using LLMs\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Load processed data from JSON\n",
    "json_path = Path(\"processed_data.json\")\n",
    "with open(json_path, \"r\") as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "# Prepare nodes and relationships\n",
    "nodes = []\n",
    "relationships = []\n",
    "\n",
    "# Formulate a prompt\n",
    "prompt = (\n",
    "    \"Extract entities and relationships from the following JSON data. For each entry in data['entities'], \"\n",
    "    \"create a 'node' dictionary with fields 'id' (unique identifier), 'name' (entity text), and 'type' (entity label). \"\n",
    "    \"For entities that have meaningful connections, define 'relationships' as dictionaries with 'source' (source node id), \"\n",
    "    \"'target' (target node id), and 'relationship' (type of connection). Create max 30 nodes, format relationships in the format of capital letters and _ inbetween words and format the entire response in the JSON output containing only variables nodes and relationships without any text inbetween\"\n",
    "    \"JSON data:\\n\"\n",
    "    f\"{json.dumps(processed_data)}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "232e1bc0-0204-455e-b605-2ec6c22aab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    base_url=\"http://host.docker.internal:11434\",\n",
    "    model=\"llama3.1\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b2ae459-97c7-4aef-9c76-9251b5f410f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\n",
    "   [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that structures data into nodes and relationships.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "text = response.content.replace(\"```json\", \"\").replace(\"```\",\"\")\n",
    "output = json.loads(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b49a798-1053-4814-9b9d-b577967cbfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': [{'id': 'node_1', 'name': 'Holden Caulfield', 'type': 'PERSON'}, {'id': 'node_2', 'name': 'New York City', 'type': 'GPE'}], 'relationships': [{'source': 'node_1', 'target': 'node_2', 'relationship': 'LOCATION_OF_RESIDENCE'}, {'source': 'node_1', 'target': 'node_1', 'relationship': 'MENTAL_HEALTH_CONDITION'}]}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0686c6c1-a8bc-4cec-baee-0d9b3fe7e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate nodes and relationships lists\n",
    "nodes.extend(output.get(\"nodes\", []))\n",
    "relationships.extend(output.get(\"relationships\", []))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c6d7c-707c-469d-b0f2-f2036c153ccb",
   "metadata": {},
   "source": [
    "# Generate Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5317447-bf52-4f02-9ddb-9d890deed3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"CREATE (n:PERSON {id: 'node_1', name: 'Holden Caulfield'})\", \"CREATE (n:GPE {id: 'node_2', name: 'New York City'})\", \"MATCH (a {id: 'node_1'}), (b {id: 'node_2'}) CREATE (a)-[:LOCATION_OF_RESIDENCE]->(b)\", \"MATCH (a {id: 'node_1'}), (b {id: 'node_1'}) CREATE (a)-[:MENTAL_HEALTH_CONDITION]->(b)\"]\n"
     ]
    }
   ],
   "source": [
    "def generate_cypher_queries(nodes, relationships):\n",
    "    queries = []\n",
    "\n",
    "    # Create nodes\n",
    "    for node in nodes:\n",
    "        query = f\"CREATE (n:{node['type']} {{id: '{node['id']}', name: '{node['name']}'}})\"\n",
    "        queries.append(query)\n",
    "\n",
    "    # Create relationships\n",
    "    for rel in relationships:\n",
    "        query = f\"MATCH (a {{id: '{rel['source']}'}}), (b {{id: '{rel['target']}'}}) \" \\\n",
    "                f\"CREATE (a)-[:{rel['relationship']}]->(b)\"\n",
    "        queries.append(query)\n",
    "\n",
    "    return queries\n",
    "\n",
    "cypher_queries = generate_cypher_queries(nodes, relationships)\n",
    "print(cypher_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f35f3-7ae6-4711-9012-df67be7c1a1d",
   "metadata": {},
   "source": [
    "# Execute Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3e29656-49dd-47c7-9276-b33c31781f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query: CREATE (n:PERSON {id: 'node_1', name: 'Holden Caulfield'})\n",
      "Executed query: CREATE (n:GPE {id: 'node_2', name: 'New York City'})\n",
      "Executed query: MATCH (a {id: 'node_1'}), (b {id: 'node_2'}) CREATE (a)-[:LOCATION_OF_RESIDENCE]->(b)\n",
      "Executed query: MATCH (a {id: 'node_1'}), (b {id: 'node_1'}) CREATE (a)-[:MENTAL_HEALTH_CONDITION]->(b)\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Initialize the Neo4j driver for Memgraph (modify the URI if necessary)\n",
    "uri = \"bolt://host.docker.internal:7687\"\n",
    "user = \"\"\n",
    "password = \"\"\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "# Function to execute Cypher queries in Memgraph\n",
    "def execute_cypher_queries(queries):\n",
    "    with driver.session() as session:\n",
    "        session.run(\"MATCH (n) DETACH DELETE n;\")\n",
    "        for query in queries:\n",
    "            try:\n",
    "                session.run(query)\n",
    "                print(f\"Executed query: {query}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing query: {query}. Error: {e}\")\n",
    "\n",
    "# Execute the generated Cypher queries\n",
    "execute_cypher_queries(cypher_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0f2f9-2ce5-4580-a798-2c70efe2144a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
